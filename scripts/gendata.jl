using Base.Filesystem
using CSV
using Comonicon
using DataFrames
using Distributed
using MLJ
using MLJLinearModels
using ProgressMeter
using Serialization
using Statistics

using RSLModels.Intervals
using RSLModels.LocalModels
using RSLModels.Parameters
using RSLModels.Tasks
using RSLModels.Utils

include("../src/gentodisk.jl")

"""
Generate a single learning task and compute learning task statistics for it.
Then store the statistics together with the parameters required to reconstruct
the learning tasks to disk; or, if `--full` is given, store the full learning
task (i.e. train/test data etc.) to disk.

# Options

- `--d, -d`:
- `--nif, -n`:
- `--N, -N`:
- `--seed`:
- `--rate-coverage-min`:
- `--remove-final-fully-overlapped`:
- `--spread-min-factor`:
- `--statsonly`: Whether to generate the data stats only (much faster due to
            much less IO esp. for many input space dimensions).
- `--prefix-fname`:
"""
@cast function gen(;
    d::Int=1,
    nif::Int=20,
    N::Int=200,
    seed::Int=0,
    rate_coverage_min::Float64=0.8,
    remove_final_fully_overlapped::Bool=false,
    statsonly::Bool=false,
    prefix_fname::String="data/$d-$nif-$N-$seed-$rate_coverage_min-$remove_final_fully_overlapped",
)
    # TODO Consider to store model (but not generated data)

    gentodisk(;
        d=d,
        nif=nif,
        N=N,
        seed=seed,
        rate_coverage_min=rate_coverage_min,
        remove_final_fully_overlapped=remove_final_fully_overlapped,
        full=!statsonly,
        prefix_fname=prefix_fname,
    )

    return nothing
end

"""
Generate one task per seed in the given range, sample it, then write the task
and the sample to disk.

# Options

- `--d, -d`:
- `--nif, -n`:
- `--N, -N`:
- `--spread-min-factor`:
- `--startseed`:
- `--endseed`:
- `--statsonly`: Whether to generate the data stats only (much faster due to
            much less IO esp. for many input space dimensions).
- `--prefix-fname`:
"""
@cast function genmany(;
    d::Int=1,
    nif::Int=3,
    N::Int=200,
    startseed::Int=0,
    endseed::Int=9,
    statsonly::Bool=false,
    prefix_fname::String="data/$d-$nif-$N",
)
    println(
        "Warning: `genmany` may not be up to date " *
        "(look at code before using it!).",
    )
    for seed in startseed:endseed
        gen(;
            d=d,
            nif=nif,
            N=N,
            seed=seed,
            statsonly=statsonly,
            prefix_fname="$prefix_fname-$seed",
        )
    end
end

"""
Generate All The Tasks per seed in the given range.

# Args

- `fname`: Name of a CSV file of the form as generated by
  `selectgendataparams.jl` providing the parameters to be used for generating
  the learning tasks.

# Options

- `--startseed`:
- `--endseed`:
- `--statsonly`: Whether to generate the data stats only (much faster due to
            much less IO esp. for many input space dimensions).
- `--usemmap`: Whether to memory-map large arrays (X, y, matching matrices, …)
            to disk and save RAM that way.
- `--prefix-fname`:
"""
@cast function genall(
    fname::String;
    startseed::Int=0,
    endseed::Int=9,
    statsonly::Bool=false,
    usemmap::Bool=false,
    prefix_fname::String="data/genstats/genall",
)
    # Start 1 additional workers.
    # addprocs(2; exeflags="--project")
    # Choose the number of workers via the `-p` parameter to Julia (probably `-p
    # auto` for as many workers as there are logical cores).
    println("Running on $(nworkers()) workers.")
    @everywhere include("../src/gentodisk.jl")
    @everywhere include("../src/Parameters.jl")

    remove_final_fully_overlapped = true

    println("Reading parameter selection from $fname …")
    df = DataFrame(CSV.File(fname))

    # Add seeds.
    df[!, :seed] = repeat([startseed:endseed], nrows(df))
    df = flatten(df, :seed)

    n_iter = nrows(df)

    # TODO Deduplicate by using Utils.onall here
    # Pattern from
    # https://github.com/timholy/ProgressMeter.jl/tree/master#tips-for-parallel-programming
    # (but fixed).
    prog = Progress(n_iter)
    channel = RemoteChannel(() -> Channel{Bool}())
    # Sync the two tasks at the very end.
    @sync begin
        # The first task updates the progress bar.
        @async while take!(channel)
            next!(prog)
        end

        # The second task does the computation.
        @async begin
            # Note that we have to add a `@sync` here since otherwise the
            # `false` is written to the channel first.
            @sync @distributed for row in eachrow(df)
                N = Parameters.n(row.DX)
                d = row.DX
                K_target = row.K
                seed = row.seed
                rate_coverage_min = row.rate_coverage_min
                # Note that the way we iterate over everything, for a fixed
                # input space dimension `d` and a fixed seed `seed`, the input
                # data points `X` are always the same for any `nif` and any
                # `rate_coverage_min` (i.e. only the outputs `y` change).
                gentodisk(;
                    d=d,
                    N=N,
                    spread_min=row.spread_min,
                    params_spread=(a=row.a, b=row.b),
                    seed=seed,
                    rate_coverage_min=rate_coverage_min,
                    K_target=K_target,
                    # TODO add remaining params here
                    remove_final_fully_overlapped=remove_final_fully_overlapped,
                    full=!statsonly,
                    usemmap=usemmap,
                    prefix_fname="$prefix_fname/$d-$K_target-$N-$seed-$rate_coverage_min-$remove_final_fully_overlapped",
                )
                # Trigger a process bar update.
                put!(channel, true)
            end
            # Tell the progress bar task to finish.
            put!(channel, false)
        end
    end
end

@main
